{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Battery_capacity(mAh)</th>\n",
       "      <th>Screen_size(inches)</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Operating system</th>\n",
       "      <th>Resolution_height(px)</th>\n",
       "      <th>Price</th>\n",
       "      <th>Internal_storage(GB)</th>\n",
       "      <th>Resolution_width(px)</th>\n",
       "      <th>Rear_Camera(MP)</th>\n",
       "      <th>Front_Camera(MP)</th>\n",
       "      <th>RAM(GB)</th>\n",
       "      <th>Number of SIMs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oneplus</td>\n",
       "      <td>4085</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>android</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>10.985276</td>\n",
       "      <td>5.549076</td>\n",
       "      <td>7.273093</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realme</td>\n",
       "      <td>4000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>android</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>10.239960</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>6.985642</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>3969</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>ios</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>11.579658</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>7.125283</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>3110</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>ios</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>11.049317</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>6.720220</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lg</td>\n",
       "      <td>4000</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>android</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>10.819598</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>6.985642</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand  Battery_capacity(mAh)  Screen_size(inches)  Processor  \\\n",
       "0  oneplus                   4085                    7          8   \n",
       "1   realme                   4000                    7          8   \n",
       "2    apple                   3969                    7          6   \n",
       "3    apple                   3110                    6          6   \n",
       "4       lg                   4000                    6          8   \n",
       "\n",
       "  Operating system  Resolution_height(px)      Price  Internal_storage(GB)  \\\n",
       "0          android                 3120.0  10.985276              5.549076   \n",
       "1          android                 2400.0  10.239960              4.174387   \n",
       "2              ios                 2688.0  11.579658              4.174387   \n",
       "3              ios                 1792.0  11.049317              4.174387   \n",
       "4          android                 2340.0  10.819598              4.859812   \n",
       "\n",
       "   Resolution_width(px)  Rear_Camera(MP)  Front_Camera(MP)   RAM(GB)  \\\n",
       "0              7.273093         3.891820          2.833213  2.564949   \n",
       "1              6.985642         4.174387          2.833213  1.945910   \n",
       "2              7.125283         2.564949          2.564949  1.609438   \n",
       "3              6.720220         2.564949          2.564949  1.609438   \n",
       "4              6.985642         2.564949          3.496508  1.945910   \n",
       "\n",
       "   Number of SIMs  \n",
       "0              16  \n",
       "1              16  \n",
       "2              16  \n",
       "3              16  \n",
       "4               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/skewed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand                     object\n",
       "Battery_capacity(mAh)      int64\n",
       "Screen_size(inches)        int64\n",
       "Processor                  int64\n",
       "Operating system          object\n",
       "Resolution_height(px)    float64\n",
       "Price                    float64\n",
       "Internal_storage(GB)     float64\n",
       "Resolution_width(px)     float64\n",
       "Rear_Camera(MP)          float64\n",
       "Front_Camera(MP)         float64\n",
       "RAM(GB)                  float64\n",
       "Number of SIMs             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "categorical_features = ['Brand', 'Operating system']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 96)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('OneHotEncoder',OneHotEncoder(), categorical_features),\n",
    "    ('MinMaxScaler', StandardScaler(), num_features)\n",
    "])\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_preprocessed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m      5\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      8\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:971\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    970\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 971\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D input, got input with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         )\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:631\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    626\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    627\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt check \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparse_container\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sparse matrix for nan or inf.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    628\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43msparse_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# TODO: Remove when the minimum version of SciPy supported is 1.12\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# With SciPy sparse arrays, conversion from DIA format to COO, CSR, or BSR\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# triggers the use of `np.int64` indices even if the data is such that it could\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# algorithms support large indices, the following code downcasts to `np.int32`\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;66;03m# indices when it's safe to do so.\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_format:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;66;03m# accept_sparse is specified to a specific format and a conversion occurred\u001b[39;00m\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_test = linear_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(linear_model, X_train, y_train, cv=5, scoring='r2')\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'Linear Regression': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Lasso Regression:  {'alpha': 1}\n",
      "MSE:  0.6120362053965209\n",
      "r2_score_train:  0.0\n",
      "r2_score_test:  -0.002937421725182965\n",
      "Cross Validation Score:  -0.0061920203840522435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "estimator = Lasso()\n",
    "paramgrid = {'alpha': list(range(1,100))}\n",
    "grid_search_lasso = GridSearchCV(estimator, paramgrid, cv=5, scoring='r2')\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "lasso_model = grid_search_lasso.best_estimator_\n",
    "\n",
    "y_pred_train = lasso_model.predict(X_train)\n",
    "y_pred_test = lasso_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(lasso_model, X_train, y_train, cv=5, scoring='r2')\n",
    "print('Best params for Lasso Regression: ', grid_search_lasso.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'Lasso Regression': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Ridge Regression:  {'alpha': 1}\n",
      "MSE:  0.1559829330816742\n",
      "r2_score_train:  0.7554569480560974\n",
      "r2_score_test:  0.7443923752244161\n",
      "Cross Validation Score:  0.7051661868608554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "estimator = Ridge()\n",
    "paramgrid = {'alpha': list(range(1,100))}\n",
    "grid_search_ridge = GridSearchCV(estimator, paramgrid, cv=5, scoring='r2')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "ridge_model = grid_search_ridge.best_estimator_ \n",
    "\n",
    "y_pred_train = ridge_model.predict(X_train)\n",
    "y_pred_test = ridge_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(ridge_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for Ridge Regression: ', grid_search_ridge.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'Ridge Regression': {'R2_Score_train': float(r2_train),'R2_Score_test':float(r2_test), 'MSE': float(mse), 'Cross Validation Score': float(cv.mean())}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for KNN Regressor:  {'n_neighbors': 8}\n",
      "MSE:  0.203720365504696\n",
      "r2_score_train:  0.7120216665972156\n",
      "r2_score_test:  0.6661655367269992\n",
      "Cross Validation Score:  0.6277932406813268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "estimator = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors': list(range(1,100))}\n",
    "grid_search_knn = GridSearchCV(estimator, param_grid, cv=5, scoring='r2')\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "knn_model = grid_search_knn.best_estimator_\n",
    "\n",
    "y_pred_train =knn_model.predict(X_train)\n",
    "y_pred_test =knn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for KNN Regressor: ', grid_search_knn.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'KNeighbors Regressor': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for DecisionTree Regressor:  {'criterion': 'squared_error', 'max_depth': 5}\n",
      "MSE:  0.21677048949320457\n",
      "r2_score_train:  0.7008563812762896\n",
      "r2_score_test:  0.6447804330504133\n",
      "Cross Validation Score:  0.5596343118346094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "estimator = DecisionTreeRegressor(random_state=42)\n",
    "paramgrid = {'max_depth': list(range(1,10)), 'criterion': ['squared_error', 'absolute_error'] }\n",
    "grid_search_decision = GridSearchCV(estimator, paramgrid, cv=5, scoring='r2')\n",
    "grid_search_decision.fit(X_train, y_train)\n",
    "decisiontree_model = grid_search_decision.best_estimator_\n",
    "\n",
    "y_pred_train = decisiontree_model.predict(X_train)\n",
    "y_pred_test = decisiontree_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(decisiontree_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for DecisionTree Regressor: ', grid_search_decision.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'DecisionTree Regression': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest Regressor:  {'criterion': 'squared_error', 'max_depth': 9, 'n_estimators': 9}\n",
      "MSE:  0.17774577794470325\n",
      "r2_score_train:  0.8442865748050865\n",
      "r2_score_test:  0.7087298256499339\n",
      "Cross Validation Score:  0.6749093959082982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "estimator = RandomForestRegressor(random_state=42)\n",
    "paramgrid = {'n_estimators': list(range(1,10)),'max_depth': list(range(1,10)), 'criterion': ['squared_error', 'absolute_error']}\n",
    "grid_search_randomforest = GridSearchCV(estimator, paramgrid, cv=5, scoring='r2')\n",
    "grid_search_randomforest.fit(X_train, y_train)\n",
    "randomforest_model = grid_search_randomforest.best_estimator_\n",
    "\n",
    "y_pred_train = randomforest_model.predict(X_train)\n",
    "y_pred_test = randomforest_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(randomforest_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for RandomForest Regressor: ', grid_search_randomforest.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'RandomForest Regression': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Adaboost Regressor:  {'learning_rate': 0.1, 'n_estimators': 6}\n",
      "MSE:  0.22319492184043005\n",
      "r2_score_train:  0.5902981498274031\n",
      "r2_score_test:  0.6342527819775495\n",
      "Cross Validation Score:  0.5686903127780095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "estimator = AdaBoostRegressor(random_state=42)\n",
    "paramgrid = {'n_estimators': list(range(1,10)), 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "grid_search_adaboost = GridSearchCV(estimator, paramgrid, cv=5, scoring='r2')\n",
    "grid_search_adaboost.fit(X_train, y_train)\n",
    "adaboost_model = grid_search_adaboost.best_estimator_\n",
    "\n",
    "y_pred_train = adaboost_model.predict(X_train)\n",
    "y_pred_test = adaboost_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(adaboost_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for Adaboost Regressor: ', grid_search_adaboost.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'AdaBoost Regressor': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jupyter Programs\\Portfolio Projects\\MobilePricePrediction\\venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Gradientboost Regressor:  {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 300}\n",
      "MSE:  0.15058193849257276\n",
      "r2_score_train:  0.8581559488924868\n",
      "r2_score_test:  0.7532429293912822\n",
      "Cross Validation Score:  0.7324726326805019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = GradientBoostingRegressor(random_state=42)\n",
    "paramgrid = {'n_estimators': [50, 100, 150, 200,250,300], 'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5,0.8,0.1], 'max_depth': list(range(1,10))}\n",
    "grid_search_gradientboost = GridSearchCV(estimator, paramgrid, cv=5, scoring='r2')\n",
    "grid_search_gradientboost.fit(X_train, y_train)\n",
    "gradientboost_model = grid_search_gradientboost.best_estimator_\n",
    "\n",
    "y_pred_train = gradientboost_model.predict(X_train)\n",
    "y_pred_test = gradientboost_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(gradientboost_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for Gradientboost Regressor: ', grid_search_gradientboost.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'GradientBoost Regressor': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Xgboost Regressor:  {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}\n",
      "MSE:  0.1501891998843222\n",
      "r2_score_train:  0.8724065532193412\n",
      "r2_score_test:  0.7538865061007933\n",
      "Cross Validation Score:  0.7299810909096693\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "estimator = XGBRegressor(random_state=42)\n",
    "param_grid = {'n_estimators': [50, 100, 150, 200], 'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5,0.8,0.1], 'max_depth': list(range(1,10)), 'gamma': [0, 0.1, 0.5,1]}\n",
    "grid_search_xgboost = GridSearchCV(estimator, param_grid, cv=5, scoring='r2')\n",
    "grid_search_xgboost.fit(X_train, y_train)\n",
    "xgboost_model = grid_search_xgboost.best_estimator_\n",
    "\n",
    "y_pred_train = xgboost_model.predict(X_train)\n",
    "y_pred_test = xgboost_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "cv = cross_val_score(xgboost_model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print('Best params for Xgboost Regressor: ', grid_search_xgboost.best_params_)\n",
    "print('MSE: ', mse)\n",
    "print('r2_score_train: ', r2_train)\n",
    "print('r2_score_test: ', r2_test)\n",
    "print('Cross Validation Score: ', cv.mean())\n",
    "\n",
    "scores.append({'Xgboost Regressor': {'R2_Score_train': r2_train,'R2_Score_test':r2_test, 'MSE': mse, 'Cross Validation Score': cv.mean()}})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Linear Regression': {'R2_Score_train': 0.7604843212165646,\n",
       "   'R2_Score_test': 0.7411758005674514,\n",
       "   'MSE': np.float64(0.15794582738073923),\n",
       "   'Cross Validation Score': np.float64(0.7034285469063831)}},\n",
       " {'Lasso Regression': {'R2_Score_train': 0.0,\n",
       "   'R2_Score_test': -0.002937421725182965,\n",
       "   'MSE': np.float64(0.6120362053965209),\n",
       "   'Cross Validation Score': np.float64(-0.0061920203840522435)}},\n",
       " {'Ridge Regression': {'R2_Score_train': 0.7554569480560974,\n",
       "   'R2_Score_test': 0.7443923752244161,\n",
       "   'MSE': 0.1559829330816742,\n",
       "   'Cross Validation Score': 0.7051661868608554}},\n",
       " {'KNeighbors Regressor': {'R2_Score_train': 0.7120216665972156,\n",
       "   'R2_Score_test': 0.6661655367269992,\n",
       "   'MSE': np.float64(0.203720365504696),\n",
       "   'Cross Validation Score': np.float64(0.6277932406813268)}},\n",
       " {'DecisionTree Regression': {'R2_Score_train': 0.7008563812762896,\n",
       "   'R2_Score_test': 0.6447804330504133,\n",
       "   'MSE': np.float64(0.21677048949320457),\n",
       "   'Cross Validation Score': np.float64(0.5596343118346094)}},\n",
       " {'RandomForest Regression': {'R2_Score_train': 0.8442865748050865,\n",
       "   'R2_Score_test': 0.7087298256499339,\n",
       "   'MSE': np.float64(0.17774577794470325),\n",
       "   'Cross Validation Score': np.float64(0.6749093959082982)}},\n",
       " {'AdaBoost Regressor': {'R2_Score_train': 0.5902981498274031,\n",
       "   'R2_Score_test': 0.6342527819775495,\n",
       "   'MSE': np.float64(0.22319492184043005),\n",
       "   'Cross Validation Score': np.float64(0.5686903127780095)}},\n",
       " {'GradientBoost Regressor': {'R2_Score_train': 0.8581559488924868,\n",
       "   'R2_Score_test': 0.7532429293912822,\n",
       "   'MSE': np.float64(0.15058193849257276),\n",
       "   'Cross Validation Score': np.float64(0.7324726326805019)}},\n",
       " {'Xgboost Regressor': {'R2_Score_train': 0.8724065532193412,\n",
       "   'R2_Score_test': 0.7538865061007933,\n",
       "   'MSE': np.float64(0.1501891998843222),\n",
       "   'Cross Validation Score': np.float64(0.7299810909096693)}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Cross Validation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.760484</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.157946</td>\n",
       "      <td>0.703429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>0.612036</td>\n",
       "      <td>-0.006192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.755457</td>\n",
       "      <td>0.744392</td>\n",
       "      <td>0.155983</td>\n",
       "      <td>0.705166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighbors Regressor</td>\n",
       "      <td>0.712022</td>\n",
       "      <td>0.666166</td>\n",
       "      <td>0.203720</td>\n",
       "      <td>0.627793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree Regression</td>\n",
       "      <td>0.700856</td>\n",
       "      <td>0.644780</td>\n",
       "      <td>0.216770</td>\n",
       "      <td>0.559634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest Regression</td>\n",
       "      <td>0.844287</td>\n",
       "      <td>0.708730</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.674909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.590298</td>\n",
       "      <td>0.634253</td>\n",
       "      <td>0.223195</td>\n",
       "      <td>0.568690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoost Regressor</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.753243</td>\n",
       "      <td>0.150582</td>\n",
       "      <td>0.732473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xgboost Regressor</td>\n",
       "      <td>0.872407</td>\n",
       "      <td>0.753887</td>\n",
       "      <td>0.150189</td>\n",
       "      <td>0.729981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  R2_Train   R2_Test       MSE  \\\n",
       "0        Linear Regression  0.760484  0.741176  0.157946   \n",
       "1         Lasso Regression  0.000000 -0.002937  0.612036   \n",
       "2         Ridge Regression  0.755457  0.744392  0.155983   \n",
       "3     KNeighbors Regressor  0.712022  0.666166  0.203720   \n",
       "4  DecisionTree Regression  0.700856  0.644780  0.216770   \n",
       "5  RandomForest Regression  0.844287  0.708730  0.177746   \n",
       "6       AdaBoost Regressor  0.590298  0.634253  0.223195   \n",
       "7  GradientBoost Regressor  0.858156  0.753243  0.150582   \n",
       "8        Xgboost Regressor  0.872407  0.753887  0.150189   \n",
       "\n",
       "   Cross Validation Score  \n",
       "0                0.703429  \n",
       "1               -0.006192  \n",
       "2                0.705166  \n",
       "3                0.627793  \n",
       "4                0.559634  \n",
       "5                0.674909  \n",
       "6                0.568690  \n",
       "7                0.732473  \n",
       "8                0.729981  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = []\n",
    "r2_train = []\n",
    "r2_test = []\n",
    "mse = []\n",
    "cv = []\n",
    "#pd.reset_option('display.float_format')\n",
    "for model in scores:\n",
    "    for name, metrics in model.items():\n",
    "        model_name.append(name)\n",
    "        r2_train.append(float(metrics['R2_Score_train']))\n",
    "        r2_test .append(float(metrics['R2_Score_test']))\n",
    "        mse.append(float(metrics['MSE']))\n",
    "        cv.append(float(metrics['Cross Validation Score']))\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    'Model': model_name,\n",
    "    'R2_Train': r2_train,\n",
    "    'R2_Test': r2_test,\n",
    "    'MSE': mse,\n",
    "    'Cross Validation Score': cv\n",
    "})\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The best model should be XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
